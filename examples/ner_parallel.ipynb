{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from collections import defaultdict, deque, namedtuple\n",
    "# from functools import partial\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Box\n",
    "from IPython.display import display\n",
    "\n",
    "import humanfriendly\n",
    "import pandas as pd\n",
    "\n",
    "from libratom.utils.pff import PffArchive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipywidgets.readthedocs.io/en/stable/examples/Output%20Widget.html#Integrating-output-widgets-with-the-logging-module\n",
    "class OutputWidgetHandler(logging.Handler):\n",
    "    \"\"\" Custom logging handler sending logs to an output widget \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(OutputWidgetHandler, self).__init__(*args, **kwargs)\n",
    "        layout = {\n",
    "            'display': 'flex',\n",
    "            'border': '1px solid lightgray',\n",
    "        }\n",
    "        self.out = widgets.Output(layout=layout)\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\" Overload of logging.Handler method \"\"\"\n",
    "        new_output = {\n",
    "            'name': 'stdout',\n",
    "            'output_type': 'stream',\n",
    "            'text': f'{self.format(record)}\\n'\n",
    "        }\n",
    "        self.out.outputs = (new_output, ) + self.out.outputs\n",
    "\n",
    "    def show_logs(self):\n",
    "        \"\"\" Show the logs \"\"\"\n",
    "        display(self.out)\n",
    "\n",
    "    def clear_logs(self):\n",
    "        \"\"\" Clear the current logs \"\"\"\n",
    "        self.out.clear_output()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = OutputWidgetHandler()\n",
    "handler.setFormatter(logging.Formatter(logging.BASIC_FORMAT))\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of PST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit as appropriate\n",
    "# CACHED_ENRON_DATA_DIR = Path(\"/tmp/libratom/test_data/RevisedEDRMv1_Complete\")\n",
    "CACHED_ENRON_DATA_DIR = Path(\"/tmp/libratom/test_data/RevisedEDRMv1_Complete/andy_zipper\")\n",
    "# CACHED_ENRON_DATA_DIR = Path(\"/tmp/libratom/test_data/RevisedEDRMv1_Complete/jason_wolfe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of files to know how many there are\n",
    "files = list(CACHED_ENRON_DATA_DIR.glob('**/*.pst'))\n",
    "\n",
    "# Overall report\n",
    "report = defaultdict(int)\n",
    "\n",
    "# List of entities to display \n",
    "ents_sample = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///ner.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# connection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class Entity(Base):\n",
    "    __tablename__ = 'entities'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    text = Column(String)\n",
    "    label_ = Column(String)\n",
    "    filename = Column(String)\n",
    "\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('entities', MetaData(bind=None), Column('id', Integer(), table=<entities>, primary_key=True, nullable=False), Column('text', String(), table=<entities>), Column('label_', String(), table=<entities>), Column('filename', String(), table=<entities>), schema=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entity.__table__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layouts\n",
    "report_box_layout = Layout(\n",
    "    display='flex',\n",
    "    width='50%',\n",
    "    margin='0px 0px 4px 0px',\n",
    "    flex_flow='column',\n",
    "    border='1px solid lightblue',\n",
    "    justify_content='center',\n",
    "    align_items='center'\n",
    ")\n",
    "\n",
    "entities_box_layout = Layout(\n",
    "    width='50%',\n",
    "    margin='0px 0px 4px 0px',\n",
    "    border='1px solid lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_report(out, data):\n",
    "    \"\"\"Refreshes the report output widget\n",
    "    \"\"\"\n",
    "\n",
    "    out.clear_output(wait=True)\n",
    "    \n",
    "    df_data = {key: [value] for key, value in data.items()}\n",
    "    df_data['Size'] = [humanfriendly.format_size(data['Size'])]\n",
    "    \n",
    "    with out:\n",
    "        display(pd.DataFrame(df_data, index=['Total']))\n",
    "\n",
    "\n",
    "def update_entities(out, data):\n",
    "    \"\"\"Refreshes the entities output widget\n",
    "    \"\"\"\n",
    "\n",
    "    out.clear_output(wait=True)\n",
    "    \n",
    "    with out:\n",
    "        print('Sample of entities found')\n",
    "        print('------------------------')\n",
    "\n",
    "        for ent in data:\n",
    "            print(f'{ent.text.strip()}: {ent.label_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    \n",
    "    try:\n",
    "        with PffArchive(file) as archive:\n",
    "            # for message in archive.messages():\n",
    "\n",
    "            return f'{multiprocessing.current_process()}: {file}, {len(list(archive.messages()))} messages'\n",
    "\n",
    "    except Exception as exc:\n",
    "        return f'{multiprocessing.current_process()}: {file}, Error: {exc}'\n",
    "        \n",
    "# def process_message(message):\n",
    "#     try:\n",
    "#         # Extract entities from the message\n",
    "#         doc = nlp(archive.format_message(message))\n",
    "#         entities = doc.ents\n",
    "# #         report['Entities'] += len(entities)\n",
    "\n",
    "#         # Show up to 10 entities\n",
    "# #         ents_sample.extendleft(entities)\n",
    "\n",
    "\n",
    "#         print(multiprocessing.current_process())\n",
    "\n",
    "\n",
    "#         # Refresh report widget every 10 messages\n",
    "# #         if not report['Messages'] % 10:\n",
    "# #             update_report(report_out, report)\n",
    "# #             update_entities(ents_out, ents_sample)\n",
    "\n",
    "#     except Exception as exc:\n",
    "#         # Log error and move on to the next message\n",
    "#         report['Errors'] += 1\n",
    "#         logger.exception(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Message generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(files):\n",
    "    # Iterate over files\n",
    "    for pst_file in files:\n",
    "        try:\n",
    "            with PffArchive(pst_file) as archive:                \n",
    "                # Iterate over messages\n",
    "                for message in archive.messages():\n",
    "                    try:\n",
    "                        yield pst_file.name, archive.format_message(message)\n",
    "                    except Exception as exc:\n",
    "                        # Log and move on to the next message\n",
    "                        logger.exception(exc)\n",
    "        except Exception as exc:\n",
    "            # Log and move on to the next file\n",
    "            logger.exception(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Entity once we have namespacing\n",
    "# EntityResult = namedtuple('EntityResult',['text','label_','filename'])\n",
    "\n",
    "def process_message(filename: str, message: str):\n",
    "    # Return basic types to avoid serialization issues\n",
    "\n",
    "    try:\n",
    "        # Extract entities from the message\n",
    "        doc = nlp(message)\n",
    "#         entities = [EntityResult(ent.text, ent.label_, filename) for ent in doc.ents]\n",
    "        \n",
    "        entities = [{'text': ent.text, 'label_': ent.label_, 'filename': filename} for ent in doc.ents]\n",
    "\n",
    "        return entities, None\n",
    "\n",
    "    except Exception as exc:\n",
    "        return None, str(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def open_db_session():\n",
    "\n",
    "    session = Session()\n",
    "    try:\n",
    "        yield session\n",
    "        session.commit()\n",
    "    except:\n",
    "        session.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize progress and report widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.clear_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar for number of files processed\n",
    "progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(files),\n",
    "    step=1,\n",
    "    description='Completed:',\n",
    "    bar_style='',\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Container for the report\n",
    "report_out = widgets.Output()\n",
    "\n",
    "# Container for the entities sample\n",
    "ents_out = widgets.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message based entities extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 1.81 s, total: 1min 2s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Can't pickle lambdas\n",
    "def job(args):\n",
    "    return process_message(*args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool() as pool, open_db_session() as session:\n",
    "        for entities, exc in pool.imap(job, get_messages(files), chunksize=100):\n",
    "            if exc:\n",
    "                logger.error(exc)\n",
    "            \n",
    "            for entity in entities:\n",
    "                new_ent = Entity(**entity)\n",
    "                session.add(new_ent)\n",
    "                \n",
    "\n",
    "# len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File based entities extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     with multiprocessing.Pool() as pool:\n",
    "#         for res in pool.map(process_file, files):\n",
    "#             print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# handler.clear_logs()\n",
    "\n",
    "# # Start displaying results\n",
    "# display(Box(children=[report_out, progress], layout=report_box_layout))\n",
    "# display(Box(children=[ents_out], layout=entities_box_layout))\n",
    "\n",
    "# # Iterate over files\n",
    "# for pst_file in files:\n",
    "#     # Update report\n",
    "#     report['Files'] += 1    \n",
    "#     report['Size'] += pst_file.stat().st_size\n",
    "    \n",
    "#     try:\n",
    "#         # Iterate over messages\n",
    "#         with PffArchive(pst_file) as archive:\n",
    "#             for message in archive.messages():\n",
    "#                 # Update report\n",
    "#                 report['Messages'] += 1\n",
    "                \n",
    "#                 try:\n",
    "#                     # Extract entities from the message\n",
    "#                     doc = nlp(archive.format_message(message))\n",
    "#                     entities = doc.ents\n",
    "#                     report['Entities'] += len(entities)\n",
    "                    \n",
    "#                     # Show up to 10 entities\n",
    "#                     ents_sample.extendleft(entities)\n",
    "\n",
    "#                     # Refresh report widget every 10 messages\n",
    "#                     if not report['Messages'] % 10:\n",
    "#                         update_report(report_out, report)\n",
    "#                         update_entities(ents_out, ents_sample)\n",
    "\n",
    "#                 except Exception as exc:\n",
    "#                     # Log error and move on to the next message\n",
    "#                     report['Errors'] += 1\n",
    "#                     logger.exception(exc)\n",
    "\n",
    "#     except Exception as exc:\n",
    "#         # Log error and move on to the next file\n",
    "#         report['Errors'] += 1\n",
    "#         logger.exception(exc)\n",
    "    \n",
    "#     # Update progress bar\n",
    "#     progress.value += 1\n",
    "    \n",
    "#     # Refresh report widget\n",
    "#     update_report(report_out, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704fbdacd9454d69a86ca61cfb6624ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid lightgray', display='flex'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out errors, if any \n",
    "handler.show_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362475"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(Entity).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Jan 2001 DATE\n",
      "05:18:00 TIME\n",
      "12 Jan 2001 DATE\n",
      "05:18:00 TIME\n",
      "MIME-Version: 1.0\n",
      " LAW\n",
      "Content-Type ORG\n",
      "Carl Carter PERSON\n",
      "Carl Carter PERSON\n",
      "Andy Zipper PERSON\n",
      "Andy Zipper PERSON\n",
      "Louise PERSON\n",
      "Louise Kitchen PERSON\n",
      "Justin Rostant PERSON\n",
      "Trade Counts ORG\n",
      "Category GPE\n",
      "January 11, 2001\n",
      " DATE\n",
      "Body-Type ORG\n",
      "EML ORG\n",
      "PST ORG\n",
      "NSF ORG\n",
      "ZL Technologies, ORG\n",
      "ZL Technologies, ORG\n",
      "11 Jan 2001 DATE\n",
      "05:11:00 TIME\n",
      "11 Jan 2001 DATE\n",
      "05:11:00 TIME\n",
      "ESBKYGKRH02BR3TIKC211PTTGIYWCWVQB@zlsvr22 NORP\n",
      "MIME-Version ORG\n",
      "1.0 CARDINAL\n",
      "Content-Type ORG\n",
      "Justin Rostant PERSON\n",
      "Andy Zipper PERSON\n",
      "Andy Zipper PERSON\n",
      "Louise PERSON\n",
      "Louise Kitchen PERSON\n",
      "Trade Counts ORG\n",
      "Category GPE\n",
      "January 10, 2001\n",
      " DATE\n",
      "Body-Type ORG\n",
      "EML ORG\n",
      "PST ORG\n",
      "NSF ORG\n",
      "ZL Technologies, ORG\n",
      "ZL Technologies, ORG\n",
      "17 Jan 2001 DATE\n",
      "05:02:00 TIME\n",
      "17 Jan 2001 DATE\n",
      "05:02:00 TIME\n",
      "MIME-Version LAW\n",
      "1.0 CARDINAL\n",
      "Content-Type ORG\n",
      "Justin Rostant PERSON\n",
      "Andy Zipper PERSON\n",
      "Andy Zipper PERSON\n",
      "Louise PERSON\n",
      "Louise Kitchen PERSON\n",
      "Trade Counts ORG\n",
      "Category GPE\n",
      "January 16, 2001\n",
      " DATE\n",
      "Body-Type ORG\n",
      "EML ORG\n",
      "PST ORG\n",
      "NSF ORG\n",
      "ZL Technologies, ORG\n",
      "ZL Technologies, ORG\n",
      "13 Jan 2001 DATE\n",
      "05:14:00 TIME\n",
      "13 Jan 2001 DATE\n",
      "05:14:00 -0800   ORG\n",
      "MIME-Version: 1.0\n",
      " LAW\n",
      "Content-Type ORG\n",
      "Justin Rostant PERSON\n",
      "Andy Zipper PERSON\n",
      "Andy Zipper PERSON\n",
      "Louise PERSON\n",
      "Louise Kitchen PERSON\n",
      "Trade Counts ORG\n",
      "Category GPE\n",
      "January 12, 2001\n",
      " DATE\n",
      "Body-Type ORG\n",
      "EML ORG\n",
      "PST ORG\n",
      "NSF ORG\n",
      "ZL Technologies, ORG\n",
      "ZL Technologies, ORG\n",
      "19 Jan 2001 DATE\n",
      "05:15:00 TIME\n",
      "Fri PERSON\n",
      "19 Jan 2001 DATE\n",
      "05:15:00 TIME\n",
      "F0OP2CZAWJ1OTHYI4LR1VPWEFRHNSJR1A@zlsvr22 PERSON\n",
      "MIME-Version ORG\n",
      "1.0 CARDINAL\n",
      "Content-Type ORG\n",
      "Justin Rostant PERSON\n",
      "Andy Zipper PERSON\n",
      "Andy Zipper PERSON\n",
      "Louise PERSON\n",
      "Louise Kitchen PERSON\n",
      "Trade Counts ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in session.query(Entity)[:100]:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
